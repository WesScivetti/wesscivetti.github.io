---
title: "Unpacking Let Alone: Human-Scale Models Generalize to a Rare Construction in Form but not Meaning"
collection: publications
category: Conference Paper
permalink: /publication/2009-10-01-paper-title-number-1
authors: "<strong>Wes Scivetti</strong>, Tatsuya Aoyama, Ethan Wilcox, Nathan Schneider"
date: 2025-11-04
venue: 'EMNLP'
paperurl: 'https://aclanthology.org/2025.emnlp-main.1399.pdf'

---
We evaluate human-scale (BabyLM) language models on the extremely rare let-alone construction, finding that they master a range of syntactic properties, but are not sensitive to the construction's semantics. We then perform a set of Filtered Corpus Training (FiCT), finding robust performance on constructional syntax even in the absence of direct observation of let-alone or related Paired Focus and Comparative Constructions.   